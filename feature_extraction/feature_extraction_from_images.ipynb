{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pramod/.local/lib/python3.5/site-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.23) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class DatasetProcessing(Dataset):\n",
    "    def __init__(self, file_list, transform=None):\n",
    "        self.img_filename = file_list\n",
    "        self.transform = transform        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_filename[index])\n",
    "        filename = self.img_filename[index]\n",
    "        img = img.convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)        \n",
    "        return img, filename\n",
    "    def __len__(self):\n",
    "        return len(self.img_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "# for testimgs\n",
    "DATA_PATH = './imgs/'\n",
    "SAVE_PATH = './test_features'\n",
    "\n",
    "use_gpu = True\n",
    "\n",
    "file_list = glob.glob(DATA_PATH+'*.jpg')\n",
    "\n",
    "print(len(file_list))\n",
    "file_list[0]\n",
    "\n",
    "import torchvision.models as models\n",
    "model = models.resnet101(pretrained=True)\n",
    "\n",
    "\"\"\"\n",
    "# remove last fully-connected layer -- for alexnet\n",
    "new_classifier = nn.Sequential(*list(model.classifier.children())[:-1])\n",
    "model.classifier = new_classifier\n",
    "\"\"\"\n",
    "\n",
    "# remove last fully-connected layer - for resnet like models \n",
    "modules=list(model.children())[:-1]\n",
    "model=nn.Sequential(*modules)\n",
    "\n",
    "#print(model)\n",
    "\n",
    "# for evaluation \n",
    "model.eval()\n",
    "\n",
    "if use_gpu:\n",
    "    print('yes')\n",
    "    model = model.cuda()\n",
    "\n",
    "batch_size = 32\n",
    "workers = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./imgs/img3.jpg\n",
      "img3.jpg\n"
     ]
    }
   ],
   "source": [
    "#file_list[0]\n",
    "\n",
    "a = file_list[0]\n",
    "print(a)\n",
    "print(a[len(DATA_PATH):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = transforms.Resize((224, 224))\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_test = DatasetProcessing(file_list, transformations)\n",
    "\n",
    "test_loader = DataLoader(dset_test,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4\n",
    "                        )\n",
    "\n",
    "dset_test.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********iter:0 *********\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "feature_df = pd.DataFrame()\n",
    "feature_dict = {}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### feature extraction phase        \n",
    "    for iter, testdata in enumerate(test_loader, 0):\n",
    "        print(\"*********iter:\" + str(iter) + ' *********')\n",
    "        test_inputs, test_file_name = testdata\n",
    "        \n",
    "        if use_gpu:\n",
    "            test_inputs = Variable(test_inputs.cuda())\n",
    "        else: test_inputs = Variable(test_inputs)\n",
    "            \n",
    "        test_outputs = model(test_inputs)\n",
    "        test_outputs = test_outputs.cpu().data.numpy()        \n",
    "        \n",
    "        # this is not required for the alexnet \n",
    "        # for resnet to squeeze the dimension from the avg pool layers\n",
    "        test_outputs = np.squeeze(test_outputs)\n",
    "        # sometimes due to the selection of a particular batch size \n",
    "        # the output becomes a 1d vector instead of bsize X dim 2d vector\n",
    "        if (len(test_outputs.shape) != 2):\n",
    "            test_outputs = np.reshape(test_outputs,(1, -1))\n",
    "        \n",
    "        for i in range(test_outputs.shape[0]):\n",
    "\n",
    "            # prepare the saving path\n",
    "            temp = test_file_name[i]\n",
    "            temp = temp[len(DATA_PATH):]\n",
    "            index = temp.find(\".jpg\")\n",
    "            temp = temp[:index]\n",
    "            feature_dict[str(temp)] = test_outputs[i,:]\n",
    "            feature_df = pd.DataFrame(feature_dict)\n",
    "            \n",
    "            \n",
    "            #save_file_name = SAVE_PATH + temp\n",
    "            #print(save_file_name)\n",
    "            \n",
    "            #np.savetxt(save_file_name, test_outputs[i,:])\n",
    "feature_df = feature_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"./test_imgs_features.csv\"\n",
    "feature_df.to_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
